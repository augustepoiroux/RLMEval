model: "hosted_vllm/deepseek-ai/DeepSeek-Prover-V1.5-RL"
temperature: 1.0
top_p: 0.95
nb_samples: 128
max_total_tokens: 4096
max_generated_tokens: 1024
use_chat_prompt: false
stopwords:
  - "```"
  - "sorry"
  - "\n\n"
n_processes: 20
gen_processes: 5
prompt_context: "FILE_CONTEXT"
nl_proof_hint: false
api_key: "-"
api_base_url: "http://localhost:8080/v1"
