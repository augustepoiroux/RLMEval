model: "hosted_vllm/deepseek-ai/DeepSeek-Prover-V1.5-RL"
temperature: 0.0
max_total_tokens: 4096
max_generated_tokens: 1024
use_chat_prompt: false
stopwords:
  - "```"
  - "sorry"
  - "\n\n"
n_processes: 20
gen_processes: 20
prompt_context: "FILE_CONTEXT_NO_LEMMAS"
nl_proof_hint: true
api_key: "-"
api_base_url: "http://localhost:8080/v1"
