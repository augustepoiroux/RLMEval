model: "gpt-4o-2024-05-13"
temperature: 0.7
top_p: 0.95
nb_samples: 50
max_total_tokens: 4096
max_generated_tokens: 512
use_chat_prompt: true
stopwords:
  - "```\n"
  - ":= by"
  - "sorry"
n_processes: 15
prompt_context: "FILE_CONTEXT"
api_key: null
api_base_url: null
